{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model\n",
    "\n",
    "This was the file used in the AWS Instance to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "Data was collected vy driving the car in the in the simulator provided. Multiple data sets were collected and used. The two that gave the best result have been shown in teh code below. All the data sets that were collected are attched in the submission. A brief Description of the data collection techniques and cahllenges faced is given below.\n",
    "\n",
    "### Data collection\n",
    "\n",
    "The different data files that were collected are as follows:\n",
    "1. Anticlockwise on Track - Fast\n",
    "2. Clockwise on Track - Slow\n",
    "\n",
    "The data sets were collected at different speed slow as well as fast to ensure the vehicle could react to different situations. All the data sets that were finally used are atleast 1 lap long. a combination of the two above was good enough to tbe able to run the car in Autonomous mode and meet the requirements. \n",
    "\n",
    "A Oython generator was not needed as the dat generated was able to run in the memory providede without any problems. Thus a generator was not implemented for this part of the project\n",
    "\n",
    "### Data Augmentation\n",
    "Now the data was augmented using two methods\n",
    "\n",
    "1. Using the left and right Camera Images to exaggerate a recovery Action\n",
    "2. Using mirror images of all the data \n",
    "\n",
    "#### Using Left and right Images\n",
    "The data collected was based on 3 cameras all facing forward but mounted on three different locations on the car Hood. \n",
    "\n",
    "The car is driven using only the center camera. Thus I made teh assumption taht if the center camera saw what the left camera saw then we are veering to the left and thus need to make a motion to the right to come back to the center of the lane. \n",
    "\n",
    "Similarly if the image seen in teh right camera is seen in teh center camera then the car is too far right nad should veer left. Thus the data was cahnged to account for this. This tripled the number of data points we have. \n",
    "\n",
    "Thus correction added\n",
    "\n",
    "1. Right image = Turn left by 0.2 Deg (Arbitrary Value)\n",
    "2. Left Image = turn right by 0.2 Deg\n",
    "3. Center Image - No Correction\n",
    "\n",
    "\n",
    "#### Using Mirror Images\n",
    "The track is a contant set of left turns (Anticlockwise) and rigth turns (Clockwise). Thus when we drive on this track we are making the model biased towards one side of the turn. Yes driving both ways means we teach teh car to turn both left and right. But while driving Anticlockwise considering the array of images we only teach it to turn left. \n",
    "\n",
    "Thus I mirrored all the data images adn reversed the steering angles for them to also teach the car to turn in the other direction. This again doubled the dataset. \n",
    "\n",
    "Thus the dataset was multiplied by 6 to teach the car different features required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9438, 160, 320, 3)\n",
      "(9438,)\n",
      "(13965, 160, 320, 3)\n",
      "(13965,)\n",
      "(27930, 160, 320, 3)\n",
      "(27930,)\n"
     ]
    }
   ],
   "source": [
    "# Creating empty arrays to store the images and the Measurements\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "#AntiClockwise data 3 (Accidentally named it CW3 but data was actually ACW3)\n",
    "lines = []\n",
    "#Open Data\n",
    "with open('/home/carnd/CW3/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "#Sort through all lines - Extract path from file - Point to path in instance - Add the image to the array\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = '/home/carnd/CW3/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        \n",
    "        #Depending on if the image is the left image or the right image or the center image add a correction. \n",
    "        # The correction is as follows:\n",
    "            #Right - Move left by 0.2 Deg\n",
    "            #Center - No Correction\n",
    "            #Left - Move Right by 0.2 Deg\n",
    "            \n",
    "        if i ==0:\n",
    "            c = 0\n",
    "        elif i == 1:\n",
    "            c = 0.2\n",
    "        else:\n",
    "            c = -0.2\n",
    "\n",
    "        measurement = float(line[3])\n",
    "        measurement = measurement+c\n",
    "        measurements.append(measurement)\n",
    "\n",
    "print(np.array(images).shape)\n",
    "print(np.array(measurements).shape)\n",
    "\n",
    "# Do the same to the next data set\n",
    "lines = []\n",
    "with open('/home/carnd/CW1/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = '/home/carnd/CW1/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        \n",
    "        if i ==0:\n",
    "            c = 0\n",
    "        elif i == 1:\n",
    "            c = 0.2\n",
    "        else:\n",
    "            c = -0.2\n",
    "\n",
    "        measurement = float(line[3])\n",
    "        measurement = measurement+c\n",
    "        measurements.append(measurement)\n",
    "\n",
    "print(np.array(images).shape)\n",
    "print(np.array(measurements).shape)\n",
    "\n",
    "#Create Augmented Image and measurement (Steering Angle) Array \n",
    "augmented_images, augmented_measurements = [],[]\n",
    "for image,measurement in zip(images,measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "print(np.array(augmented_images).shape)\n",
    "print(np.array(augmented_measurements).shape)\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Used\n",
    "\n",
    "A convolution Neurral network with a flatten nural network with one output node was used to train the model. \n",
    "\n",
    "The data was first Noralized adn mean centered so taht any features that were biased in teh data do not affect the learning too much.\n",
    "\n",
    "The image was then cropped to only look at the road and remove the part of the image that looks at the trees and the sky. \n",
    "\n",
    "The CNN is made up of 4 Convolution Layers with Relu Activation and Max Pooling at every stage. \n",
    "\n",
    "The filter sizze for the first two layers is 5X5 and the filter size for the last two layers is 3X3\n",
    "\n",
    "The depth begins at 3 for the image and then is increased to 6 then 18 then 36 and finally 48 by the final layer. \n",
    "\n",
    "A dropout layer was added after the final convolution layer to ensure we do not overfit tot he data. I had initially added dropouts to every layer and was running into significant issues with learning the features and thus kept decreasing the number of dropout layers until this configuration gave me the desired result.\n",
    "\n",
    "After this we have a flat Neural network going from 512 - 256 - 128 - 32 - 1 nodes. Th eoutput of this is the steering angle of the car.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model used to train - model Architecture is explained in the next Block\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Activation, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Data is Normalized and Mean centered\n",
    "model.add(Lambda(lambda x:((x/255.0)-0.5),input_shape = (160,320,3)))\n",
    "#Data is cropped such that a part of the sky that is not required is removed\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "#Convolution layer with filter of 5X5 and depth of 6 with a relu activation\n",
    "model.add(Convolution2D(6,5,5,activation='relu'))\n",
    "#Max Pooling along a 2X2 filter\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#Convolution layer with filter of 5X5 and depth of 18 with a relu activation\n",
    "model.add(Convolution2D(18,5,5,activation='relu'))\n",
    "#Max Pooling along a 2X2 filter\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#Convolution layer with filter of 3X3 and depth of 36 with a relu activation\n",
    "model.add(Convolution2D(36,3,3,activation='relu'))\n",
    "#Max Pooling along a 2X2 filter\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#Convolution layer with filter of 3X3 and depth of 4 with a relu activation\n",
    "model.add(Convolution2D(48,3,3,activation='relu'))\n",
    "#Max Pooling along a 2X2 filter\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#Dropout layer to reduce overfitting - ignoring half th generated points\n",
    "model.add(Dropout(0.5))\n",
    "# Flatten the network\n",
    "model.add(Flatten())\n",
    "#Layer 2 512 Nodes with relu activation\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "#Layer 3 256 Nodes with relu activation\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "#Layer 4 128 Nodes with relu activation\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "#Layer 5 32 Nodes with relu activation\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "#Output layer with a steering angle prediction\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trining the model on the data\n",
    "\n",
    "The data is split into a training set and a validation set. \n",
    "\n",
    "An adam optimiser is then used to train the model and get the necessary output.\n",
    "\n",
    "The model was then saved and used to drive the Simulator on the local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22344 samples, validate on 5586 samples\n",
      "Epoch 1/2\n",
      "22344/22344 [==============================] - 48s - loss: 0.0118 - val_loss: 0.0234\n",
      "Epoch 2/2\n",
      "22344/22344 [==============================] - 47s - loss: 0.0070 - val_loss: 0.0285\n"
     ]
    }
   ],
   "source": [
    "#adam Optimiser used so Learning rate was automatically tuned\n",
    "model.compile(loss ='mse',optimizer = 'adam')\n",
    "#Data was split into Test and Validation Set and then fit onto the model described above\n",
    "model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch=2)\n",
    "#Model is saved\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
